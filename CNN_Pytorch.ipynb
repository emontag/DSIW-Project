{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch implementation of Google Landmark Recognition Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needed imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu=True #change as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import np as tnp# Torch wrapper for Numpy\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "size=32,32\n",
    "from PIL import ImageFile#needed for working with some images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wd = os.path.join(os.getcwd(),'train')\n",
    "test_wd = os.path.join(os.getcwd(), 'test')\n",
    "print (train_wd)\n",
    "print (test_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "trainfiles = [f for f in listdir(train_wd) if isfile(join(train_wd, f))]\n",
    "testfiles = [f for f in listdir(test_wd) if isfile(join(test_wd,f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trainfiles)) # 235813\n",
    "print(len(testfiles)) # 7166"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "all_train = {}\n",
    "iter = 0\n",
    "\n",
    "with open(os.path.join(os.getcwd(), 'train.csv')) as train_csvfile:\n",
    "    reader = csv.DictReader(train_csvfile)\n",
    "    # create lookup dictionary for images that have been successfully downloaded\n",
    "    for row in reader:\n",
    "        all_train[row['id']] = row['landmark_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run this code if need to delete bad images. Otherwise takes time for no purpose. Rerun notebook after running this\n",
    "#This deletes images that cause CNN to fail training. Run script until no errors (should only be needed once). Ensure this has no errors \n",
    "#Make sure to reload data from above\n",
    "\"\"\"\n",
    "import cv2\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "itr = 0\n",
    "img_size = (32,32)\n",
    "for filename in trainfiles:\n",
    "    p=os.path.join(train_wd,filename)\n",
    "    img = cv2.imread(p,0) # 0 second input for greyscale.\n",
    "\n",
    "    # flatten image\n",
    "    try:\n",
    "        img = cv2.resize(img, img_size).flatten()\n",
    "    except Exception:\n",
    "        print (filename +\" is a bad image. Removing from dataset. From opencv\")\n",
    "        os.remove(p)\n",
    "        continue\n",
    "    try:\n",
    "        img=Image.open(p)\n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize((32, 32), Image.ANTIALIAS)\n",
    "    except Exception:\n",
    "        print (filename +\" is a bad image. Removing from dataset. From PIL\")\n",
    "        os.remove(p)\n",
    "        continue\n",
    "    itr = itr + 1\n",
    "    if itr % 10000 == 0:\n",
    "        print(itr)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of labels to be able to split\n",
    "train_labels=[]\n",
    "for filename in trainfiles:\n",
    "    fn = filename.replace('.jpg','')\n",
    "    train_labels.append(all_train[fn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation setup and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not run for validation\n",
    "X=np.array(trainfiles)\n",
    "y=np.array(train_labels)\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest=train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len (Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding of labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb_temp=mlb.fit_transform(tnp.array(train_labels)).astype(tnp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/mratsim/starting-kit-for-pytorch-deep-learning\n",
    "\n",
    "#Class loads and transforms image files and labels as needed\n",
    "#This class allows not all images to be stored at once in memory. Handles batches well. \n",
    "#Do all image changes here (though Augmentation pipeline is preferred to be used)\n",
    "\n",
    "class LoadDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, data,  transform=None):\n",
    "    \n",
    "        #tmp_df = pd.read_csv(csv_path)\n",
    "        \n",
    "        \n",
    "        #self.mlb = MultiLabelBinarizer()\n",
    "        self.img_path = path\n",
    "        #self.img_ext = \".jpg\"\n",
    "        self.transform = transform\n",
    "\n",
    "        self.X_train = data\n",
    "        #self.y_train = self.mlb.fit_transform(all_train['id'].str.split()).astype(np.float32)\n",
    "        self.train_labels = []\n",
    "        itr = 0\n",
    "        img_size = (32,32)\n",
    "        for filename in self.X_train:\n",
    "\n",
    "            # find targets\n",
    "            fn = filename.replace('.jpg','')\n",
    "            train_labels.append(all_train[fn])\n",
    "            \n",
    "            itr = itr + 1\n",
    "            #if itr % 10000 == 0:\n",
    "            #    print(itr)\n",
    "        #self.y_train=self.mlb.fit_transform(tnp.array(train_labels)).astype(tnp.float32)#one hot encoding reverse by \n",
    "        #mlb.inverse_transform(predictions\n",
    "        self.y_train=mlb_temp\n",
    "        #self.y_train=np.array(list(all_labels), dtype=np.int32)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_path , self.X_train[index]))\n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize((32, 32), Image.ANTIALIAS)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        #label = torch.from_numpy(self.y_train[index])\n",
    "        label=torch.from_numpy(np.array([self.y_train[index]], dtype=np.int32)).float()\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up pytorch train Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up transformations for images and set u data loader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "     [transforms.Resize(32),\n",
    "     #transforms.RandomCrop(256),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "dset_train = LoadDataset(train_wd, Xtrain, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_gpu:\n",
    "    train_loader = DataLoader(dset_train,\n",
    "                          batch_size=50,#can be changed depending if GPU has enough memory\n",
    "                          shuffle=True,\n",
    "                          num_workers=0 # 0 works higher seems not to prrobably jupyter notebook\n",
    "                          #pin_memory=True # CUDA only\n",
    "                         )\n",
    "else:\n",
    "    train_loader = DataLoader(dset_train,\n",
    "                          batch_size=50,#can be changed depending if GPU has enough memory\n",
    "                          shuffle=True,\n",
    "                          num_workers=0, # 1 for CUDA (0 always works) must be 0 \n",
    "                          pin_memory=True # CUDA only\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN class that assumes size of images will be 256x256 and labels are of tensor size 10. \n",
    "#Must change values here if size changes.\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        #self.fc1 = nn.Linear(2304, 256)\n",
    "        #self.fc1=nn.Linear(246016,256)\n",
    "        self.fc1=nn.Linear(2304,50)\n",
    "        #self.fc2 = nn.Linear(256, 10)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        #self.fc2 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(x.size(0), -1) # Flatten layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "if not use_gpu:\n",
    "    model = Net() # On CPU\n",
    "else:\n",
    "    model = Net().cuda() # On GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this for both training and validation\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion =nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(async=True), target.cuda(async=True) # On GPU\n",
    "        data, target = Variable (data), Variable (target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #loss = F.CrossEntropyLoss(output, target)\n",
    "        loss = criterion(output, torch.max(target, 1)[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "        del data, target\n",
    "        if use_gpu:\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trains data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, 1):\n",
    "    train(epoch)\n",
    "#model.eval() for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run to clear up memory if want to go straight to validation withouyt saving\n",
    "del train_loader\n",
    "if use_gpu:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run so can keep train and test data seperate if need restart kernel (out of memory)\n",
    "torch.save(model.state_dict(), 'checkpoint.pth')\n",
    "with open(\"test_filenames.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(Xtest, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/42703500/best-way-to-save-a-trained-model-in-pytorch\n",
    "\n",
    "#only run if need load in data and model from disk (typically from a kernel restart)\n",
    "#Or just run it because you can\n",
    "# Warning: Running this without having both a checkpoint in current working directory and the test_filenames \n",
    "if not use_gpu:\n",
    "    model=Net()\n",
    "else:\n",
    "    model=Net().cuda()\n",
    "model.load_state_dict(torch.load('checkpoint.pth'))\n",
    "with open(\"test_filenames.txt\", \"rb\") as fp:   # Unpickling\n",
    "    Xtest = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "model.eval()\n",
    "#torch.cuda.empty_cache()\n",
    "transform = transforms.Compose(\n",
    "     [transforms.Resize(32),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "dset_test = LoadDataset(train_wd, Xtest, transform)\n",
    "if use_gpu:\n",
    "    validation_loader = DataLoader(dset_test,\n",
    "                          batch_size=50,\n",
    "                          shuffle=False,\n",
    "                          num_workers=0, # 1 for CUDA\n",
    "                          pin_memory=True # CUDA only\n",
    "                         )\n",
    "else:\n",
    "    validation_loader = DataLoader(dset_test,\n",
    "                          batch_size=50,\n",
    "                          shuffle=False,\n",
    "                          num_workers=0 # 1 for CUDA\n",
    "                          #pin_memory=True # CUDA only\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=50\n",
    "from sklearn.metrics import f1_score\n",
    "def validate():\n",
    "    count=0\n",
    "    accuracy=0\n",
    "    for batch_idx, (data, target) in enumerate(validation_loader):\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(async=True), target.cuda(async=True) # On GPU\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        #print(target)\n",
    "        #print(mlb.inverse_transform(output.data))\n",
    "        #print(output.data.numpy())#take 1 row at a time transform it and can compare labels or just compare to target\n",
    "        #accuracy = 100 * correct / total\n",
    "        #print(accuracy)\n",
    "        loss = criterion(output, torch.max(target, 1)[1])\n",
    "        losses.append(loss.data[0])\n",
    "        if batch_idx%100 == 0:\n",
    "            pass\n",
    "        t=None\n",
    "        o=None\n",
    "        if use_gpu:\n",
    "            t=target.cpu().data.numpy()\n",
    "            o=output.cpu().data.numpy()\n",
    "        else:\n",
    "            t=target.data.numpy()\n",
    "            o=output.data.numpy()\n",
    "        #print (t[0])\n",
    "        #print (o[0])\n",
    "        del data,target\n",
    "        for i in range(batch_size):#todo test this out\n",
    "            count +=1\n",
    "            try:\n",
    "                if np.array_equal(t[i],o[i]):\n",
    "                    accuracy += 1\n",
    "            except Exception:\n",
    "                continue\n",
    "        print (\"Batch number \", batch_idx, \" just passed\")\n",
    "        #acc=f1_score(target, output, average='macro')  \n",
    "        #print(\"Batch: \", batch_idx,\"Accuracy: \", acc)\n",
    "    print(sum(losses)/len(losses))\n",
    "    print (\"accuracy: \", accuracy/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate()\n",
    "#look at visdom for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del validation_loader\n",
    "if use_gpu:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only run if want to see GPU memory allocation\n",
    "#http://forums.fast.ai/t/gpu-memory-not-being-freed-after-training-is-over/10265/8\n",
    "def pretty_size(size):\n",
    "    \"\"\"Pretty prints a torch.Size object\"\"\"\n",
    "    assert(isinstance(size, torch.Size))\n",
    "    return \" × \".join(map(str, size))\n",
    "\n",
    "def dump_tensors(gpu_only=True):\n",
    "    \"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
    "    import gc\n",
    "    total_size = 0\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj):\n",
    "                if not gpu_only or obj.is_cuda:\n",
    "                    print(\"%s:%s%s %s\" % (type(obj).__name__, \n",
    "                                          \" GPU\" if obj.is_cuda else \"\",\n",
    "                                        \" pinned\" if obj.is_pinned else \"\",\n",
    "                                          pretty_size(obj.size())))\n",
    "                    total_size += obj.numel()\n",
    "            elif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "                if not gpu_only or obj.is_cuda:\n",
    "                    print(\"%s → %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
    "                                                    type(obj.data).__name__, \n",
    "                                                    \" GPU\" if obj.is_cuda else \"\",\n",
    "                                                    \" pinned\" if obj.data.is_pinned else \"\",\n",
    "                                                    \" grad\" if obj.requires_grad else \"\", \n",
    "                                                    \" volatile\" if obj.volatile else \"\",\n",
    "                                                    pretty_size(obj.data.size())))\n",
    "                    total_size += obj.data.numel()\n",
    "        except Exception as e:\n",
    "            pass        \n",
    "    print(\"Total size:\", total_size)\n",
    "dump_tensors(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
